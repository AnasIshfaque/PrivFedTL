{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3a8eee-bdd5-4d26-b741-104a061957e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import medmnist\n",
    "from medmnist import BreastMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60aafffb-6543-45d6-a018-e291fd24c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LeNet model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=1, hidden=768, num_classes=2):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440bd21f-446a-426f-b0cf-65ed338002d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(img1, img2):\n",
    "    return ((img1 - img2) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9190df-a2a4-4834-a8ce-f075379a57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize weights\n",
    "def weights_init(m):\n",
    "    try:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print(f'Warning: failed in weights_init for {m._get_name()}.weight')\n",
    "    try:\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print(f'Warning: failed in weights_init for {m._get_name()}.bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "971b6515-2727-4e1c-bb5d-6257ddde754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BreastMNIST dataset\n",
    "def load_breastmnist(data_flag='train'):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = BreastMNIST(split=data_flag, download=True, transform=transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea485a0-2830-43be-8b2d-9c0a52fed370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: BreastMNIST, device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = 'BreastMNIST'\n",
    "num_classes = 2\n",
    "channel = 1\n",
    "hidden = 588\n",
    "lr = 1.0\n",
    "num_dummy = 1\n",
    "Iteration = 50\n",
    "num_exp = 3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "print(f'Using dataset: {dataset}, device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591d8966-c265-4cdc-8a40-5e24be99c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "lpips_model = lpips.LPIPS(net='alex').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0134d8fb-3af1-4267-a442-937deff4ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dst = load_breastmnist()\n",
    "dataloader = DataLoader(dst, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bef64b16-a7b1-4f14-b013-8d22182742c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1/3 experiment\n",
      "Iteration 1: Loss=0.000202, MSE=1.107912, SSIM=0.000532, LPIPS=0.487206\n",
      "Iteration 6: Loss=0.000005, MSE=0.193219, SSIM=0.109814, LPIPS=0.257825\n",
      "Iteration 11: Loss=0.000000, MSE=0.039441, SSIM=0.476558, LPIPS=0.119238\n",
      "Iteration 16: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 21: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 26: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 31: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 36: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 41: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 46: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Iteration 50: Loss=0.000000, MSE=0.028182, SSIM=0.581216, LPIPS=0.093872\n",
      "Experiment 1\n",
      "Running 2/3 experiment\n",
      "Iteration 1: Loss=16.957926, MSE=0.781006, SSIM=0.014709, LPIPS=0.531675\n",
      "Iteration 6: Loss=0.012822, MSE=0.012339, SSIM=0.790329, LPIPS=0.040851\n",
      "Iteration 11: Loss=0.001101, MSE=0.001646, SSIM=0.951483, LPIPS=0.005541\n",
      "Iteration 16: Loss=0.000380, MSE=0.000626, SSIM=0.977480, LPIPS=0.000869\n",
      "Iteration 21: Loss=0.000161, MSE=0.000266, SSIM=0.989828, LPIPS=0.000236\n",
      "Iteration 26: Loss=0.000094, MSE=0.000169, SSIM=0.994313, LPIPS=0.000139\n",
      "Iteration 31: Loss=0.000069, MSE=0.000113, SSIM=0.996607, LPIPS=0.000080\n",
      "Iteration 36: Loss=0.000054, MSE=0.000089, SSIM=0.997480, LPIPS=0.000051\n",
      "Iteration 41: Loss=0.000039, MSE=0.000073, SSIM=0.997943, LPIPS=0.000036\n",
      "Iteration 46: Loss=0.000039, MSE=0.000067, SSIM=0.998156, LPIPS=0.000032\n",
      "Iteration 50: Loss=0.000034, MSE=0.000062, SSIM=0.998250, LPIPS=0.000030\n",
      "Experiment 2\n",
      "Running 3/3 experiment\n",
      "Iteration 1: Loss=4.185788, MSE=0.516841, SSIM=0.026342, LPIPS=0.548543\n",
      "Iteration 6: Loss=0.002396, MSE=0.002231, SSIM=0.936374, LPIPS=0.011242\n",
      "Iteration 11: Loss=0.000337, MSE=0.000473, SSIM=0.987622, LPIPS=0.000827\n",
      "Iteration 16: Loss=0.000119, MSE=0.000168, SSIM=0.995832, LPIPS=0.000305\n",
      "Iteration 21: Loss=0.000063, MSE=0.000084, SSIM=0.997981, LPIPS=0.000153\n",
      "Iteration 26: Loss=0.000043, MSE=0.000050, SSIM=0.998829, LPIPS=0.000063\n",
      "Iteration 31: Loss=0.000029, MSE=0.000030, SSIM=0.999258, LPIPS=0.000028\n",
      "Iteration 36: Loss=0.000021, MSE=0.000018, SSIM=0.999485, LPIPS=0.000013\n",
      "Iteration 41: Loss=0.000018, MSE=0.000014, SSIM=0.999614, LPIPS=0.000009\n",
      "Iteration 46: Loss=0.000014, MSE=0.000011, SSIM=0.999676, LPIPS=0.000007\n",
      "Iteration 50: Loss=0.000013, MSE=0.000009, SSIM=0.999729, LPIPS=0.000007\n",
      "Experiment 3\n"
     ]
    }
   ],
   "source": [
    "for idx_net in range(num_exp):\n",
    "    net = LeNet(channel=channel, hidden=hidden, num_classes=num_classes)\n",
    "    net.apply(weights_init)\n",
    "    net.to(device)\n",
    "    \n",
    "    print(f'Running {idx_net+1}/{num_exp} experiment')\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.view(-1).long()\n",
    "        break  # Get a single batch\n",
    "    \n",
    "    # Compute original gradient\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    out = net(data)\n",
    "    loss = criterion(out, target)\n",
    "    dy_dx = torch.autograd.grad(loss, net.parameters())\n",
    "    original_dy_dx = [_.detach().clone() for _ in dy_dx]\n",
    "    \n",
    "    # Generate dummy data\n",
    "    dummy_data = torch.randn_like(data, requires_grad=True, device=device)\n",
    "    # dummy_label = torch.randn((data.shape[0], num_classes), requires_grad=True, device=device)\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS([dummy_data], lr=lr)\n",
    "    label_pred = torch.argmin(torch.sum(original_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,))\n",
    "\n",
    "    history = []\n",
    "    history_iters = []\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(dummy_data)\n",
    "        dummy_loss = criterion(pred, label_pred)\n",
    "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "        grad_diff = sum(((gx - gy) ** 2).sum() for gx, gy in zip(dummy_dy_dx, original_dy_dx))\n",
    "        grad_diff.backward()\n",
    "        return grad_diff\n",
    "        \n",
    "    for iters in range(Iteration):\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Compute loss, MSE, SSIM and LPIP\n",
    "        with torch.no_grad():\n",
    "            mse_val = compute_mse(dummy_data.cpu().numpy(), data.cpu().numpy())\n",
    "            ssim_val = ssim(dummy_data.cpu().squeeze().numpy(), data.cpu().squeeze().numpy(), data_range=1)\n",
    "            \n",
    "            resize_transform = transforms.Resize((32, 32))\n",
    "            dummy_resized = resize_transform(dummy_data)\n",
    "            data_resized = resize_transform(data)\n",
    "            lpips_val = lpips_model(dummy_resized, data_resized).item()\n",
    "        \n",
    "        if iters % (Iteration // 10) == 0 or (iters+1) == Iteration:\n",
    "            print(f\"Iteration {iters+1}: Loss={closure().item():.6f}, MSE={mse_val:.6f}, SSIM={ssim_val:.6f}, LPIPS={lpips_val:.6f}\")\n",
    "            history.append(dummy_data.detach().cpu().squeeze().numpy())\n",
    "            history_iters.append(iters)\n",
    "    \n",
    "    print(f'Experiment {idx_net+1}')\n",
    "    fig, axes = plt.subplots(1, len(history) + 2, figsize=(15, 3))\n",
    "    for i, (img, iter_num) in enumerate(zip(history, history_iters)):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"Iter {iter_num}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    axes[-2].imshow(dummy_data.detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[-2].set_title(f\"Iter {history_iters[-1]}\")\n",
    "    axes[-2].axis('off')\n",
    "    axes[-2].text(0.5, -0.15, f\"Pred: {label_pred.item()}\", size=12, ha=\"center\", va=\"top\", transform=axes[-2].transAxes)\n",
    "\n",
    "    axes[-1].imshow(data.cpu().squeeze(), cmap='gray')\n",
    "    axes[-1].set_title(\"Original\")\n",
    "    axes[-1].axis('off')\n",
    "    axes[-1].text(0.5, -0.15, f\"Label: {target.item()}\", size=12, ha=\"center\", va=\"top\", transform=axes[-1].transAxes)\n",
    "    \n",
    "    plt.savefig(f\"reconstruction_progress_exp{idx_net+1}.png\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
