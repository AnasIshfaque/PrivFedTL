{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3a8eee-bdd5-4d26-b741-104a061957e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import medmnist\n",
    "from medmnist import BreastMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60aafffb-6543-45d6-a018-e291fd24c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LeNet model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=1, hidden=768, num_classes=2):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440bd21f-446a-426f-b0cf-65ed338002d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(img1, img2):\n",
    "    return ((img1 - img2) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9190df-a2a4-4834-a8ce-f075379a57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize weights\n",
    "def weights_init(m):\n",
    "    try:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            m.weight.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print(f'Warning: failed in weights_init for {m._get_name()}.weight')\n",
    "    try:\n",
    "        if hasattr(m, \"bias\"):\n",
    "            m.bias.data.uniform_(-0.5, 0.5)\n",
    "    except Exception:\n",
    "        print(f'Warning: failed in weights_init for {m._get_name()}.bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971b6515-2727-4e1c-bb5d-6257ddde754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BreastMNIST dataset\n",
    "def load_breastmnist(data_flag='train'):\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = BreastMNIST(split=data_flag, download=True, transform=transform)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea485a0-2830-43be-8b2d-9c0a52fed370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset: BreastMNIST, device: cuda\n"
     ]
    }
   ],
   "source": [
    "dataset = 'BreastMNIST'\n",
    "num_classes = 2\n",
    "channel = 1\n",
    "hidden = 588\n",
    "lr = 1.0\n",
    "num_dummy = 1\n",
    "Iteration = 50\n",
    "num_exp = 3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if use_cuda else 'cpu'\n",
    "\n",
    "print(f'Using dataset: {dataset}, device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591d8966-c265-4cdc-8a40-5e24be99c2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/anas/PrivFedTL/anasenv/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "lpips_model = lpips.LPIPS(net='alex').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0134d8fb-3af1-4267-a442-937deff4ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dst = load_breastmnist()\n",
    "dataloader = DataLoader(dst, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78a4c95-9a7e-4090-9601-88ebbfa61b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits_scale = 26\n",
    "\n",
    "# Create TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, 31]\n",
    ")\n",
    "\n",
    "# set the scale\n",
    "context.global_scale = pow(2, bits_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef64b16-a7b1-4f14-b013-8d22182742c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1/3 experiment\n"
     ]
    }
   ],
   "source": [
    "for idx_net in range(num_exp):\n",
    "    net = LeNet(channel=channel, hidden=hidden, num_classes=num_classes)\n",
    "    net.apply(weights_init)\n",
    "    net.to(device)\n",
    "    \n",
    "    print(f'Running {idx_net+1}/{num_exp} experiment')\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.view(-1).long()\n",
    "        break  # Get a single batch\n",
    "    \n",
    "    # Compute original gradient\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    out = net(data)\n",
    "    loss = criterion(out, target)\n",
    "    dy_dx = torch.autograd.grad(loss, net.parameters())\n",
    "    original_dy_dx = [_.detach().clone() for _ in dy_dx]\n",
    "\n",
    "    #encrypting gradients\n",
    "    encrypted_dy_dx = []\n",
    "    for param in original_dy_dx:\n",
    "        plain_ten = ts.plain_tensor(param.cpu())\n",
    "        encrypted_ten = ts.ckks_tensor(context, plain_ten)\n",
    "        encrypted_dy_dx.append(encrypted_ten)\n",
    "\n",
    "    # print('shape of dy_dx:')\n",
    "    # for param in original_dy_dx: \n",
    "    #     print(param.shape)\n",
    "\n",
    "    # print('shape of encrypted dy_dx:')\n",
    "    # for param in encrypted_dy_dx: \n",
    "    #     print(param.shape)\n",
    "    \n",
    "    # Generate dummy data\n",
    "    dummy_data = torch.randn_like(data, requires_grad=True, device=device)\n",
    "    dummy_label = torch.randn((data.shape[0], num_classes), requires_grad=True, device=device)\n",
    "    \n",
    "    optimizer = torch.optim.LBFGS([dummy_data, dummy_label], lr=lr)\n",
    "    # label_pred = torch.argmin(torch.sum(encrypted_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,))\n",
    "\n",
    "    history = []\n",
    "    history_iters = []\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(dummy_data)\n",
    "        # dummy_loss = criterion(pred, label_pred)\n",
    "        dummy_loss = - torch.mean(torch.sum(torch.softmax(dummy_label, -1) * torch.log(torch.softmax(pred, -1)), dim=-1))\n",
    "        dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
    "        # grad_diff = sum(((gx - gy) ** 2).sum() for gx, gy in zip(dummy_dy_dx, encrypted_dy_dx))\n",
    "        encrypted_dummy_dy_dx = []\n",
    "        for gradient in dummy_dy_dx:\n",
    "            plain_gradient = ts.plain_tensor(gradient.detach().cpu())\n",
    "            encrypted_gradient = ts.ckks_tensor(context, plain_gradient)\n",
    "            encrypted_dummy_dy_dx.append(encrypted_gradient)\n",
    "\n",
    "        # Perform gradient difference calculation homomorphically\n",
    "        encrypted_grad_diffs = []\n",
    "        for gx, gy in zip(encrypted_dummy_dy_dx, encrypted_dy_dx):\n",
    "            encrypted_diff = gx.sub(gy)\n",
    "            encrypted_squared_diff = encrypted_diff.mul(encrypted_diff)\n",
    "            encrypted_summed_diff = encrypted_squared_diff.sum()\n",
    "            encrypted_grad_diffs.append(encrypted_summed_diff)\n",
    "\n",
    "        # Sum all the differences\n",
    "        encrypted_total_grad_diff = encrypted_grad_diffs[0]\n",
    "        for i in range(1, len(encrypted_grad_diffs)):\n",
    "            encrypted_total_grad_diff = encrypted_total_grad_diff.add(encrypted_grad_diffs[i])\n",
    "\n",
    "        encrypted_total_grad_diff.backward()\n",
    "        return encrypted_total_grad_diff\n",
    "        \n",
    "    for iters in range(Iteration):\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Compute loss, MSE, SSIM and LPIP\n",
    "        with torch.no_grad():\n",
    "            mse_val = compute_mse(dummy_data.cpu().numpy(), data.cpu().numpy())\n",
    "            ssim_val = ssim(dummy_data.cpu().squeeze().numpy(), data.cpu().squeeze().numpy(), data_range=1)\n",
    "            \n",
    "            resize_transform = transforms.Resize((32, 32))\n",
    "            dummy_resized = resize_transform(dummy_data)\n",
    "            data_resized = resize_transform(data)\n",
    "            lpips_val = lpips_model(dummy_resized, data_resized).item()\n",
    "        \n",
    "        if iters % (Iteration // 10) == 0 or (iters+1) == Iteration:\n",
    "            print(f\"Iteration {iters+1}: Loss={closure().item():.6f}, MSE={mse_val:.6f}, SSIM={ssim_val:.6f}, LPIPS={lpips_val:.6f}\")\n",
    "            history.append(dummy_data.detach().cpu().squeeze().numpy())\n",
    "            history_iters.append(iters)\n",
    "    \n",
    "    print(f'Experiment {idx_net+1}')\n",
    "    fig, axes = plt.subplots(1, len(history) + 2, figsize=(15, 3))\n",
    "    for i, (img, iter_num) in enumerate(zip(history, history_iters)):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"Iter {iter_num}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    axes[-2].imshow(dummy_data.detach().cpu().squeeze(), cmap='gray')\n",
    "    axes[-2].set_title(f\"Iter {history_iters[-1]}\")\n",
    "    axes[-2].axis('off')\n",
    "    axes[-2].text(0.5, -0.15, f\"Pred: {torch.argmax(dummy_label, dim=-1).detach().item()}\", size=12, ha=\"center\", va=\"top\", transform=axes[-2].transAxes)\n",
    "\n",
    "    axes[-1].imshow(data.cpu().squeeze(), cmap='gray')\n",
    "    axes[-1].set_title(\"Original\")\n",
    "    axes[-1].axis('off')\n",
    "    axes[-1].text(0.5, -0.15, f\"Label: {target.item()}\", size=12, ha=\"center\", va=\"top\", transform=axes[-1].transAxes)\n",
    "    \n",
    "    plt.savefig(f\"reconstruction_progress_exp{idx_net+1}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de378cf7-bb77-4134-8424-66f9abb31ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
